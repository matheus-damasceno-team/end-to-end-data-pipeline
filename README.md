# Modern Data Pipeline para Agroneg√≥cio

> Um pipeline de dados moderno e de c√≥digo aberto, demonstrando uma arquitetura completa para o agroneg√≥cio, desde a ingest√£o de dados em tempo real at√© a entrega de modelos de Machine Learning como uma API de scoring de cr√©dito.

[![Me Pague um Caf√©](https://img.shields.io/badge/-Me%20Pague%20um%20Caf%C3%A9-FFDD00?style=for-the-badge&logo=buy-me-a-coffee&logoColor=black)](https://mepagaumcafe.com.br/matheushrd)


### ‚ú® Tecnologias Principais

![Python](https://img.shields.io/badge/Python-3776AB?logo=python&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?logo=docker&logoColor=white)
![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-231F20?logo=apache-kafka&logoColor=white)
![Apache Spark](https://img.shields.io/badge/Apache%20Spark-E25A1C?logo=apache-spark&logoColor=white)
![Apache Iceberg](https://img.shields.io/badge/Apache%20Iceberg-1890FF?logo=apache&logoColor=white)
![Trino](https://img.shields.io/badge/Trino-DB1B21?logo=trino&logoColor=white)
![dbt](https://img.shields.io/badge/dbt-FF694B?logo=dbt&logoColor=white)
![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?logo=apache-airflow&logoColor=white)
![Feast](https://img.shields.io/badge/Feast-1D324A?logo=feast&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-009688?logo=fastapi&logoColor=white)
![MinIO](https://img.shields.io/badge/MinIO-C72C48?logo=minio&logoColor=white)
![Apache Hive](https://img.shields.io/badge/Apache%20Hive-FDEE21?logo=apache-hive&logoColor=black)
![Redis](https://img.shields.io/badge/Redis-DC382D?logo=redis&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-4169E1?logo=postgresql&logoColor=white)
![MariaDB](https://img.shields.io/badge/MariaDB-003545?logo=mariadb&logoColor=white)

---

## üèóÔ∏è Arquitetura Detalhada

Esta arquitetura foi desenhada para ser uma plataforma de dados robusta, escal√°vel e modular, totalmente baseada em tecnologias open-source. A filosofia √© desacoplar os componentes, permitindo que cada ferramenta execute sua fun√ß√£o especializada, desde a ingest√£o at√© a entrega de insights.

-   **Funda√ß√£o (Data Lakehouse):** O n√∫cleo da arquitetura √© o **Data Lakehouse**, que combina a flexibilidade de um Data Lake com a confiabilidade de um Data Warehouse.
    -   **MinIO** atua como o storage de objetos, oferecendo uma camada de armazenamento escal√°vel e compat√≠vel com S3.
    -   **Apache Iceberg** √© o formato de tabela aberta que gerencia os dados no MinIO. Ele adiciona uma camada transacional (ACID), versionamento de dados (*time travel*), e evolu√ß√£o de schema, tratando os dados no lake como tabelas de banco de dados confi√°veis.
    -   O **Hive Metastore** (com backend em MariaDB) centraliza todos os metadados (schemas, parti√ß√µes, etc.), permitindo que diferentes motores de processamento (Spark, Trino) acessem os mesmos dados de forma consistente.

-   **Fluxo de Dados (Pipeline):** O fluxo segue o padr√£o **Medallion (Bronze, Silver, Gold)**.
    -   **Ingest√£o (Real-time):** Dados s√£o produzidos em formato **Avro** (definido em `producer_schema.avsc`), que garante um schema forte e compress√£o eficiente. O **Kafka** atua como um buffer, desacoplando os produtores dos consumidores e garantindo a entrega das mensagens.
    -   **Processamento e Transforma√ß√£o:**
        -   **Apache Spark** √© usado para a ingest√£o inicial (streaming), lendo do Kafka e escrevendo na camada Bronze.
        -   **Trino** √© o motor de consulta federado, otimizado para consultas anal√≠ticas de baixa lat√™ncia diretamente no Data Lakehouse.
        -   **dbt** orquestra as transforma√ß√µes SQL via Trino. Ele transforma os dados brutos (Bronze) em dados limpos e enriquecidos (Silver) e, em seguida, em modelos de neg√≥cio agregados (Gold), prontos para an√°lise e ML.

-   **Orquestra√ß√£o e MLOps:**
    -   **Apache Airflow** √© o c√©rebro da opera√ß√£o, orquestrando todos os pipelines de forma agendada. Ele dispara os jobs do dbt e o pipeline de retreinamento de modelos de ML.
    -   **Feast** serve como uma **Feature Store**, criando uma ponte entre a engenharia de dados e a ci√™ncia de dados. Ele materializa features da camada Gold para um **Online Store (Redis)**, garantindo acesso de baixa lat√™ncia para a API de infer√™ncia.
    -   A **API (FastAPI)** serve o modelo de ML e √© o ponto de entrada para os consumidores finais. Ela √© desacoplada do treinamento, apenas carregando o modelo mais recente.

![Arquitetura Completa](images/complete_architecture.png)

## ü§ñ Como Usar a API de Scoring

A API de scoring de cr√©dito √© o produto final deste pipeline. Para interagir com ela, voc√™ pode usar a interface do Streamlit ou fazer requisi√ß√µes diretas.

### Testando com o Script Automatizado

O projeto inclui um script de teste (`test_api.sh`) que simula diferentes cen√°rios de requisi√ß√£o.

1.  **Navegue at√© o diret√≥rio do script:**
    ```bash
    cd services/credit_scoring_api/test_payloads/
    ```

2.  **Execute o script:**
    -   Para testar todos os cen√°rios (aprova√ß√£o, revis√£o manual e nega√ß√£o):
        ```bash
        ./test_api.sh
        ```
    -   Para testar um cen√°rio espec√≠fico, como o de aprova√ß√£o:
        ```bash
        ./test_api.sh approve_case.json
        ```
    -   Para ver as informa√ß√µes do modelo atualmente em produ√ß√£o:
        ```bash
        ./test_api.sh --model-info
        ```

O script verifica a sa√∫de da API, envia os payloads dos arquivos JSON, e exibe tanto a requisi√ß√£o quanto a resposta formatada, indicando o sucesso ou falha de cada caso.

## üîç O Pipeline em Detalhes

1.  **Ingest√£o (Real-Time - Camada Bronze):**
    -   O `producer-simulator` cria mensagens no formato **Avro**, que √© bin√°rio, compacto e suporta evolu√ß√£o de schema, ideal para streaming de dados.
    -   Um job de **Spark Streaming** (`ingestion_to_iceberg.py`) consome continuamente do Kafka. Este √© um processamento *real-time*.
    -   **Benef√≠cio:** Os dados chegam √† camada **Bronze** (tabela Iceberg) com lat√™ncia de segundos, preservando o dado bruto e original para futuras an√°lises. O Iceberg garante que cada escrita seja uma transa√ß√£o at√¥mica.

2.  **Transforma√ß√£o (NRT - Camada Silver):**
    -   Uma DAG do Airflow (`dbt_trino_silver_dag`) √© executada em modo *Near Real-Time* (NRT), por exemplo, a cada 5 minutos.
    -   Ela executa os modelos do dbt que transformam os dados da camada Bronze. As transforma√ß√µes s√£o **incrementais**, utilizando a estrat√©gia `merge` do Iceberg.
    -   **Benef√≠cio:** Apenas os dados novos ou atualizados s√£o processados, o que √© extremamente eficiente. O dbt permite que essas transforma√ß√µes sejam modulares, test√°veis e documentadas, garantindo a qualidade da camada **Silver**.

3.  **Agrega√ß√£o (Batch - Camada Gold):**
    -   Outra DAG (`dbt_trino_gold_dag`) √© executada em modo *batch* (ex: a cada hora), pois agrega√ß√µes de neg√≥cio n√£o exigem a mesma lat√™ncia.
    -   Ela cria as tabelas da camada **Gold**, que cont√™m as *features* agregadas (ex: `proponente_features_agro`) prontas para serem consumidas por dashboards ou pelo pipeline de ML.
    -   **Benef√≠cio:** A camada Gold √© a "fonte da verdade" para o neg√≥cio, com m√©tricas e features pr√©-calculadas, otimizando as consultas finais.

4.  **Retreinamento Autom√°tico do Modelo (MLOps):**
    -   A DAG `ml_model_training_dag` representa um ciclo de MLOps automatizado.
    -   **Detec√ß√£o de Drift:** Primeiro, ela verifica se houve *data drift*, comparando a distribui√ß√£o dos dados atuais da camada Gold com uma janela hist√≥rica.
    -   **Retreinamento:** Se um drift significativo √© detectado ou se o modelo agendado para retreino (ex: a cada 6 horas) √© acionado, a DAG treina um novo modelo `RandomForestClassifier` com os dados mais recentes.
    -   **Avalia√ß√£o e Deploy:** O novo modelo √© avaliado contra o modelo anterior. Se a performance (ex: F1-score) for superior, o novo artefato (`credit_model.joblib`) √© salvo no diret√≥rio compartilhado.
    -   **Restart da API:** Por fim, a DAG reinicia o cont√™iner da API para que ela carregue o novo modelo sem downtime.
    -   **Benef√≠cio:** O sistema se adapta automaticamente a mudan√ßas no padr√£o dos dados, garantindo que o modelo em produ√ß√£o seja sempre o mais perform√°tico poss√≠vel, sem interven√ß√£o manual.

## üìñ Tabelas do Pipeline de Dados

O pipeline de dados √© estruturado seguindo a metodologia Medallion (Bronze, Silver, Gold), garantindo a qualidade e a governan√ßa dos dados em cada etapa.

### ü•â Camada Bronze

A camada Bronze armazena os dados brutos, exatamente como chegam da fonte, com o m√≠nimo de processamento.

-   **Tabela:** `bronze.dados_produtores_agro`
-   **Origem:** Job Spark `ingestion_to_iceberg.py`.
-   **Descri√ß√£o:** Esta tabela Iceberg recebe os dados em streaming do t√≥pico Kafka `dados_produtores`. Ela armazena os registros no formato original Avro, incluindo todas as estruturas aninhadas (`localizacao_propriedade`, `fontes_dados_adicionais`, `metadata_evento`). A tabela √© particionada por m√™s (`ingestion_timestamp`) e `tipo_pessoa` para otimizar as consultas na camada seguinte. O objetivo √© ter uma c√≥pia fiel e imut√°vel dos dados de origem.
-   **Schema:**
    ```sql
    proponente_id STRING,
    data_solicitacao LONG,
    cpf_cnpj STRING,
    nome_razao_social STRING,
    tipo_pessoa STRING,
    renda_bruta_anual_declarada DOUBLE,
    valor_solicitado_credito DOUBLE,
    finalidade_credito STRING,
    localizacao_propriedade STRUCT<latitude: DOUBLE, longitude: DOUBLE, municipio: STRING, uf: STRING>,
    area_total_hectares DOUBLE,
    cultura_principal STRING,
    possui_experiencia_atividade BOOLEAN,
    anos_experiencia INT,
    fontes_dados_adicionais STRUCT<serasa_score: INT, ibama_autuacoes_ativas: BOOLEAN, numero_matricula_imovel: STRING>,
    metadata_evento STRUCT<versao_schema: STRING, origem_dados: STRING, timestamp_geracao_evento: LONG>,
    ingestion_timestamp TIMESTAMP
    ```

### ü•à Camada Silver

A camada Silver transforma os dados brutos em um formato mais limpo, validado e enriquecido, pronto para an√°lise.

-   **Tabela:** `silver.silver_dados_produtores_agro_trino`
-   **Origem:** Modelo dbt `silver_dados_produtores_agro_trino.sql`.
-   **Descri√ß√£o:** Este modelo dbt l√™ os dados da tabela Bronze, realiza as seguintes transforma√ß√µes e materializa o resultado de forma incremental:
    -   **Desaninhamento (Flattening):** Extrai campos de estruturas aninhadas (como `latitude` e `longitude`) para colunas de primeiro n√≠vel.
    -   **Type Casting:** Converte timestamps (de Unix milissegundos para o formato `TIMESTAMP WITH TIME ZONE`).
    -   **Limpeza:** Renomeia colunas para um padr√£o mais claro (ex: `latitude` para `localizacao_latitude`).
    -   **Enriquecimento:** Adiciona novas colunas de neg√≥cio, como:
        -   `classificacao_propriedade`: Classifica a propriedade em `MINIFUNDIO`, `PEQUENA`, `MEDIA` ou `GRANDE` com base na √°rea.
        -   `faixa_risco_credito`: Define uma faixa de risco (`BAIXO`, `MEDIO`, `ALTO`) com base no `serasa_score`.
    -   **Valida√ß√£o:** Cria a coluna booleana `registro_valido` para sinalizar registros que atendem a crit√©rios m√≠nimos de qualidade.
-   **Schema (Principais Campos):**
    ```sql
    proponente_id STRING,
    data_solicitacao TIMESTAMP(6) WITH TIME ZONE,
    cpf_cnpj STRING,
    tipo_pessoa STRING,
    valor_solicitado_credito DOUBLE,
    finalidade_credito STRING,
    localizacao_latitude DOUBLE,
    localizacao_longitude DOUBLE,
    localizacao_municipio STRING,
    localizacao_uf STRING,
    area_total_hectares DOUBLE,
    cultura_principal STRING,
    anos_experiencia INT,
    serasa_score INT,
    ibama_autuacoes_ativas BOOLEAN,
    classificacao_propriedade STRING, -- Campo enriquecido
    faixa_risco_credito STRING,      -- Campo enriquecido
    registro_valido BOOLEAN,         -- Campo de valida√ß√£o
    processed_at TIMESTAMP(6) WITH TIME ZONE -- Timestamp do processamento
    ```

### ü•á Camada Gold

A camada Gold cont√©m dados agregados e focados em casos de uso de neg√≥cio espec√≠ficos, como a cria√ß√£o de features para modelos de Machine Learning.

-   **Tabela 1:** `gold.proponente_features_agro`
    -   **Origem:** Modelo dbt `proponente_features_agro.sql`.
    -   **Descri√ß√£o:** Agrega os dados da camada Silver para criar features centradas em cada `proponente_id`.
    -   **Schema (Principais Features):**
        ```sql
        proponente_id STRING,
        total_solicitacoes BIGINT,
        valor_medio_solicitado DOUBLE,
        serasa_score_medio DOUBLE,
        ultima_solicitacao TIMESTAMP(6) WITH TIME ZONE,
        dias_entre_primeira_ultima BIGINT,
        taxa_autuacoes_ibama DOUBLE,
        perfil_frequencia STRING, -- Ex: 'NOVO', 'RECORRENTE'
        perfil_volatilidade STRING, -- Ex: 'CONSISTENTE', 'VOLATIL'
        feature_timestamp TIMESTAMP(6) WITH TIME ZONE
        ```

-   **Tabela 2:** `gold.location_features_agro`
    -   **Origem:** Modelo dbt `location_features_agro.sql`.
    -   **Descri√ß√£o:** Agrega os dados por localiza√ß√£o (`UF` e `munic√≠pio`) para criar features que descrevem o comportamento do agroneg√≥cio em n√≠vel regional.
    -   **Schema (Principais Features):**
        ```sql
        localizacao_uf STRING,
        localizacao_municipio STRING,
        total_proponentes BIGINT,
        valor_medio_solicitado DOUBLE,
        area_media_hectares DOUBLE,
        cultura_dominante STRING,
        taxa_risco_elevado DOUBLE, -- % de solicita√ß√µes com risco ALTO ou MUITO_ALTO
        densidade_proponentes STRING, -- Ex: 'BAIXA', 'ALTA'
        feature_timestamp TIMESTAMP(6) WITH TIME ZONE
        ```

-   **Tabela 3:** `gold.risk_features_agro`
    -   **Origem:** Modelo dbt `risk_features_agro.sql`.
    -   **Descri√ß√£o:** Cria features agregadas por `faixa_risco_credito` e `cultura_principal` para an√°lise de risco por segmento.
    -   **Schema (Principais Features):**
        ```sql
        faixa_risco_credito STRING,
        cultura_principal STRING,
        total_solicitacoes BIGINT,
        valor_mediano DOUBLE,
        serasa_score_medio DOUBLE,
        taxa_pessoa_juridica DOUBLE,
        score_risco_ajustado DOUBLE, -- Score de risco calculado
        volatilidade_credito STRING, -- Ex: 'HOMOGENEO', 'VOLATIL'
        feature_timestamp TIMESTAMP(6) WITH TIME ZONE
        ```

## ‚òÅÔ∏è De Open Source para a Nuvem (AWS)

Este projeto foi constru√≠do com ferramentas open-source, o que √© ideal para aprendizado e desenvolvimento local sem custos. No entanto, a arquitetura √© diretamente traduz√≠vel para um ambiente de nuvem como a AWS, usando servi√ßos gerenciados que oferecem escalabilidade, seguran√ßa e menor sobrecarga operacional.

Estudar e dominar esta stack open-source fornece uma base s√≥lida para trabalhar com os seguintes servi√ßos da AWS:

| Ferramenta Open-Source | Servi√ßo Equivalente na AWS | Descri√ß√£o da Similaridade |
| :--- | :--- | :--- |
| **Docker Compose** | **AWS Copilot / ECS / EKS** | Orquestra√ß√£o de cont√™ineres para rodar os microsservi√ßos. |
| **Apache Kafka** | **Amazon MSK** | Servi√ßo gerenciado de streaming com Kafka. |
| **MinIO** | **Amazon S3** | Armazenamento de objetos para o Data Lake. |
| **Apache Spark** | **AWS Glue / Amazon EMR** | Processamento de dados serverless (Glue) ou em clusters gerenciados (EMR). |
| **Apache Iceberg** | **Apache Iceberg on Glue/EMR** | O formato de tabela √© suportado nativamente nos servi√ßos da AWS. |
| **Hive Metastore** | **AWS Glue Data Catalog** | Cat√°logo de metadados centralizado e serverless. |
| **Trino** | **Amazon Athena** | Servi√ßo de consulta SQL serverless, baseado em Trino/Presto. |
| **dbt** | **dbt Cloud / dbt Core on EC2/ECS** | O dbt se conecta nativamente ao Redshift, Athena, etc. |
| **Apache Airflow** | **Amazon MWAA** | Servi√ßo gerenciado de orquestra√ß√£o com Airflow. |
| **Feast + Redis** | **Amazon SageMaker Feature Store** | Feature store gerenciada para ML. |
| **FastAPI on Docker** | **AWS Lambda + API Gateway / SageMaker Endpoints** | Deploy de APIs serverless ou endpoints de ML gerenciados. |
| **PostgreSQL/MariaDB** | **Amazon RDS** | Banco de dados relacional gerenciado. |

**Vantagem de Aprender com Open Source:** Entender como cada pe√ßa (Kafka, Spark, Trino, etc.) funciona individualmente e se integra com as outras fornece um conhecimento profundo que √© muitas vezes abstra√≠do pelos servi√ßos gerenciados da nuvem. Isso o torna um profissional mais completo, capaz de diagnosticar problemas, otimizar custos e escolher a ferramenta certa para cada trabalho, seja na nuvem ou on-premises.


## üöÄ Como Executar o Projeto

### Pr√©-requisitos

-   **Docker:** [Instru√ß√µes de instala√ß√£o](https://docs.docker.com/get-docker/)
-   **Docker Compose:** Geralmente inclu√≠do na instala√ß√£o do Docker.
-   **Git:** Para clonar o reposit√≥rio.
-   **M√≠nimo de 16GB de RAM** alocada para o Docker.
-   **SO Recomendado** Linux.
-   **Obs.:** Ao usar WSL nota-se a necessidade de mais mem√≥ria RAM.

### Passos para a Instala√ß√£o

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone https://github.com/matheushrd/modern-data-pipeline.git
    cd modern-data-pipeline
    ```

2.  **Inicie todos os servi√ßos com Docker Compose:**
    Este comando ir√° baixar as imagens e iniciar os cont√™ineres em segundo plano (`-d`).
    ```bash
    docker-compose up -d
    ```

3.  **Execute o script de setup:**
    Este script realiza configura√ß√µes essenciais, como criar os t√≥picos no Kafka, os buckets no MinIO e inicializar as configura√ß√µes do dbt e do Feast.
    ```bash
    ./setup.sh
    ```

### ‚úÖ Verificando a Instala√ß√£o

Ap√≥s a execu√ß√£o do `setup.sh`, o pipeline come√ßar√° a processar os dados. Voc√™ pode verificar o status:

-   **Airflow UI:** Acesse `http://localhost:8086` e verifique se as DAGs (`dbt_trino_silver_dag`, `ml_model_training_dag`, etc.) est√£o sendo executadas com sucesso.
-   **MinIO Console:** Acesse `http://localhost:9001` e verifique se os buckets (`bronze`, `silver`, `gold`) foram criados e cont√™m dados.
-   **Kafka UI:** Acesse `http://localhost:8085` para ver os t√≥picos e as mensagens fluindo.

### üîó Acessando os Servi√ßos

| Servi√ßo | URL | Credenciais |
| :--- | :--- | :--- |
| **Airflow UI** | `http://localhost:8086` | `airflow` / `airflow` |
| **Trino UI** | `http://localhost:8080` | `admin` (sem senha) |
| **Kafka UI** | `http://localhost:8085` | - |
| **MinIO Console** | `http://localhost:9001` | `admin` / `password` |
| **Streamlit App** | `http://localhost:8501` | - |
| **API Docs** | `http://localhost:8087/docs` | - |

## ü§ñ Como Usar a API de Scoring

Voc√™ pode enviar uma requisi√ß√£o `POST` para a API para obter um score de cr√©dito. Use o `id_proponente` para consultar features da online store do Feast.

**Exemplo de Requisi√ß√£o `curl`:**

```bash
curl -X 'POST' \
  'http://localhost:8087/v1/credit-score' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json' \
  -d '{
  "id_proponente": "proponente_123",
  "uf": "SP",
  "renda_liquida_mes": 15000,
  "valor_solicitado": 50000,
  "prazo": 24
}'
```

## üîç O Pipeline em Detalhes

1.  **Produ√ß√£o de Dados:** O servi√ßo `producer_simulator` gera dados e os envia para o t√≥pico `proponentes_credito` no `kafka`.
2.  **Ingest√£o (Bronze):** O job `ingestion-consumer` (Spark) consome os dados do Kafka e os salva como tabelas Iceberg no `minio`, na camada Bronze. Os metadados s√£o gerenciados pelo `metastore`.
3.  **Limpeza e Enriquecimento (Silver):** A DAG `dbt_trino_silver_dag` no `airflow` orquestra o `dbt-trino` para transformar os dados brutos, criando a camada Silver.
4.  **Agrega√ß√£o (Gold):** A DAG `dbt_trino_gold_dag` faz o mesmo para a camada Gold, criando features de neg√≥cio.
5.  **Treinamento do Modelo:** A DAG `ml_model_training_dag` treina, avalia e versiona um modelo de classifica√ß√£o, salvando o artefato.
6.  **Deploy e Infer√™ncia:** O servi√ßo `credit-scoring-api` carrega o modelo treinado. Ao receber uma requisi√ß√£o, ele busca features em tempo real do `feast` (que usa `redis`) para realizar a infer√™ncia e retornar o score.

## üìÇ Estrutura do Projeto

```
.
‚îú‚îÄ‚îÄ airflow/                 # DAGs e configura√ß√µes do Airflow
‚îú‚îÄ‚îÄ conf/                    # Configura√ß√µes de conectores do Trino
‚îú‚îÄ‚îÄ dbt_trino/               # Projeto dbt para transforma√ß√µes
‚îú‚îÄ‚îÄ feast_repo/              # Defini√ß√µes da Feature Store do Feast
‚îú‚îÄ‚îÄ images/                  # Diagramas e imagens do projeto
‚îú‚îÄ‚îÄ services/                # C√≥digo-fonte dos microsservi√ßos
‚îÇ   ‚îú‚îÄ‚îÄ credit_scoring_api/  # API de scoring de cr√©dito (FastAPI)
‚îÇ   ‚îú‚îÄ‚îÄ ingestion_consumer/  # Consumidor Spark (Kafka -> Bronze)
‚îÇ   ‚îú‚îÄ‚îÄ producer_simulator/  # Simulador de dados para o Kafka
‚îÇ   ‚îî‚îÄ‚îÄ streamlit_app/       # Aplica√ß√£o web de monitoramento
‚îú‚îÄ‚îÄ docker-compose.yml       # Orquestra√ß√£o de todos os servi√ßos
‚îî‚îÄ‚îÄ setup.sh                 # Script de inicializa√ß√£o do ambiente
```

## ü§ù Como Contribuir

Contribui√ß√µes s√£o muito bem-vindas! Se voc√™ tem alguma sugest√£o ou encontrou um bug, por favor, abra uma **issue** ou envie um **pull request**.

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo [LICENSE](/LICENSE) para mais detalhes.

## üó∫Ô∏è Roadmap: Evoluindo para uma Plataforma de Dados Completa

Esta arquitetura √© uma base s√≥lida e funcional. No entanto, para transform√°-la em uma plataforma de dados de n√≠vel enterprise, robusta, observ√°vel e segura, os pr√≥ximos passos se concentram em tr√™s pilares estrat√©gicos: **Governan√ßa de Dados**, **Observabilidade Total** e **Automa√ß√£o e Seguran√ßa**.

O objetivo deste roadmap n√£o √© apenas adicionar mais ferramentas, mas preencher lacunas cr√≠ticas que surgem quando um pipeline de dados cresce em escala e import√¢ncia para o neg√≥cio.

---

### üèõÔ∏è Pilar 1: Governan√ßa de Dados e Qualidade

√Ä medida que mais dados e usu√°rios s√£o adicionados, garantir a confian√ßa, a descoberta e a qualidade dos dados se torna a principal prioridade.

| Evolu√ß√£o Proposta | Ferramenta Open-Source | Justificativa Estrat√©gica (Por qu√™?) | Servi√ßo Equivalente na AWS |
| :--- | :--- | :--- | :--- |
| **1. Data Catalog & Linhagem** | **OpenMetadata / DataHub** | **Problema:** "De onde veio este dado? Quem √© o dono? Posso confiar nele?". O Hive Metastore √© t√©cnico; falta uma camada de neg√≥cio para documenta√ß√£o, descoberta e, crucialmente, **linhagem de dados de ponta a ponta** (de Kafka √† API). | **AWS Glue Data Catalog (com DataZone)** |
| **2. Schema Registry** | **Confluent Schema Registry** | **Problema:** Mudan√ßas no schema do produtor podem quebrar silenciosamente os consumidores. Um Schema Registry for√ßa um "contrato de dados" (Data Contract), garantindo a compatibilidade e a evolu√ß√£o segura dos schemas Avro. | **AWS Glue Schema Registry** |
| **3. Monitoramento de Qualidade** | **Great Expectations / Soda Core** | **Problema:** Os testes do dbt s√£o √≥timos, mas reativos. Precisamos de **monitoramento proativo da qualidade dos dados** diretamente no pipeline (ex: no job Spark de ingest√£o) para detectar anomalias, dados inv√°lidos e desvios antes que eles contaminem o Data Lake. | **AWS Deequ / AWS Glue Data Quality** |

---

### üî≠ Pilar 2: Observabilidade Total (M√©tricas, Logs e Traces)

Uma plataforma de dados sem visibilidade √© uma caixa preta. A observabilidade nos permite entender o comportamento do sistema, diagnosticar problemas rapidamente e garantir a performance.

| Evolu√ß√£o Proposta | Ferramenta Open-Source | Justificativa Estrat√©gica (Por qu√™?) | Servi√ßo Equivalente na AWS |
| :--- | :--- | :--- | :--- |
| **1. M√©tricas e Alertas** | **Prometheus + Grafana** | **Problema:** "O Kafka est√° lento? O Spark est√° usando todos os recursos?". Precisamos coletar m√©tricas de todos os servi√ßos (Kafka, Trino, Spark, APIs) em um √∫nico local, criar dashboards de sa√∫de e configurar alertas para condi√ß√µes anormais (ex: lat√™ncia alta, fila do Kafka crescendo). | **Amazon Managed Service for Prometheus + Amazon Managed Grafana / CloudWatch** |
| **2. Agrega√ß√£o de Logs** | **Loki / OpenSearch** | **Problema:** Diagnosticar um erro hoje exige `docker logs` em m√∫ltiplos cont√™ineres. Uma solu√ß√£o de logging centralizado permite pesquisar e analisar todos os logs da aplica√ß√£o e do sistema em uma √∫nica interface, correlacionando eventos entre servi√ßos. | **Amazon OpenSearch Service / CloudWatch Logs** |
| **3. Tracing Distribu√≠do** | **OpenTelemetry + Jaeger/Tempo** | **Problema:** "Por que esta requisi√ß√£o na API demorou 3 segundos?". O tracing distribu√≠do permite seguir uma √∫nica requisi√ß√£o atrav√©s de todos os microsservi√ßos (API -> Feast -> Trino), visualizando o tempo gasto em cada etapa e identificando gargalos. | **AWS X-Ray** |

---

### üõ°Ô∏è Pilar 3: Automa√ß√£o, Seguran√ßa e Analytics

Com a governan√ßa e a observabilidade estabelecidas, o foco se volta para a automa√ß√£o do ciclo de vida de desenvolvimento, o fortalecimento da seguran√ßa e a democratiza√ß√£o do acesso aos dados.

| Evolu√ß√£o Proposta | Ferramenta Open-Source | Justificativa Estrat√©gica (Por qu√™?) | Servi√ßo Equivalente na AWS |
| :--- | :--- | :--- | :--- |
| **1. Pipeline de CI/CD** | **GitHub Actions / GitLab CI** | **Problema:** O deploy √© manual (`docker-compose up`). Um pipeline de CI/CD automatiza testes (unit√°rios, de integra√ß√£o, testes do dbt) e o deploy de novas vers√µes, garantindo que mudan√ßas no c√≥digo n√£o quebrem o ambiente e acelerando o desenvolvimento. | **AWS CodePipeline / CodeBuild** |
| **2. Gerenciamento de Segredos** | **HashiCorp Vault** | **Problema:** Segredos (senhas, chaves de API) est√£o em texto plano no `docker-compose.yml`. O Vault centraliza e protege o acesso a esses segredos, permitindo que as aplica√ß√µes os obtenham de forma segura e audit√°vel. | **AWS Secrets Manager / Parameter Store** |
| **3. Plataforma de BI** | **Apache Superset / Metabase** | **Problema:** O Streamlit √© excelente para apps de dados, mas n√£o substitui uma ferramenta de BI para explora√ß√£o e cria√ß√£o de dashboards pelo time de neg√≥cio. Uma plataforma de BI se conectaria ao Trino para democratizar o acesso aos dados da camada Gold. | **Amazon QuickSight** |

---

### üèõÔ∏è Pilar 4: Escalabilidade Cloud-Native e GitOps

Com a base s√≥lida, o pr√≥ximo salto de maturidade √© adotar a orquestra√ß√£o e as pr√°ticas de implanta√ß√£o que s√£o padr√£o na nuvem, garantindo escalabilidade real e um gerenciamento de infraestrutura declarativo.

| Evolu√ß√£o Proposta | Ferramenta Open-Source | Justificativa Estrat√©gica (Por qu√™?) | Servi√ßo Equivalente na AWS |
| :--- | :--- | :--- | :--- |
| **1. Orquestra√ß√£o de Cont√™ineres** | **Kubernetes (k8s)** | **Problema:** O Docker Compose √© excelente para desenvolvimento local, mas n√£o oferece auto-recupera√ß√£o (self-healing), escalabilidade horizontal ou gerenciamento avan√ßado de rede e armazenamento para um ambiente de produ√ß√£o. O Kubernetes √© o padr√£o para executar aplica√ß√µes distribu√≠das em escala. | **Amazon EKS (Elastic Kubernetes Service)** |
| **2. Continuous Delivery com GitOps** | **Argo CD** | **Problema:** Um pipeline de CI/CD (Pilar 3) constr√≥i e testa os artefatos, mas como garantimos que o estado do nosso cluster Kubernetes corresponde exatamente ao que foi definido e testado? O Argo CD implementa o **GitOps**, usando um reposit√≥rio Git como a √∫nica fonte da verdade para o estado da aplica√ß√£o, automatizando e auditando o deploy de forma cont√≠nua e segura. | **Argo CD on EKS** (Combina√ß√£o padr√£o) |