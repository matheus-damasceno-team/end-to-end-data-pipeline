networks:
  agri_platform_net:
    driver: bridge

volumes:
  minio_data:
  postgres_hive_data:
  postgres_superset_data:
  clickhouse_data:
  redis_data:

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: zookeeper
    networks:
      - agri_platform_net
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_SYNC_LIMIT: 2
    ports:
      - "2181:2181"
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 30s
      timeout: 10s
      retries: 5

  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka
    networks:
      - agri_platform_net
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_CONFLUENT_SCHEMA_REGISTRY_URL: http://schema-registry:8081
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 5

  minio:
    image: minio/minio:latest
    container_name: minio
    networks:
      - agri_platform_net
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio_data:/data
    environment:
      MINIO_ROOT_USER: admin
      MINIO_ROOT_PASSWORD: password123
      MINIO_SERVER_URL: http://minio:9000
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3

  mc:
    image: minio/mc:latest
    container_name: mc
    networks:
      - agri_platform_net
    depends_on:
      minio:
        condition: service_healthy
    environment:
      MC_HOST_localminio: http://admin:password123@minio:9000
    entrypoint: >
      /bin/sh -c "
      echo 'Configurando MinIO Client...' &&
      until mc alias set localminio http://minio:9000 admin password123; do
        echo 'Aguardando MinIO...' && sleep 2;
      done;
      echo 'MinIO Client configurado com sucesso';
      mc ls localminio || mc mb localminio/datalake;
      mc mb localminio/warehouse || true;
      mc mb localminio/feast-registry || true;
      echo 'Buckets criados com sucesso';
      tail -f /dev/null;
      "

  postgres_hive:
    image: postgres:15-alpine
    container_name: postgres_hive
    networks:
      - agri_platform_net
    ports:
      - "5432:5432"
    environment:
      POSTGRES_DB: metastore
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hivepassword
    volumes:
      - postgres_hive_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U hive -d metastore"]
      interval: 10s
      timeout: 5s
      retries: 5

  hive-metastore:
    image: apache/hive:3.1.3
    container_name: hive-metastore
    networks:
      - agri_platform_net
    depends_on:
      postgres_hive:
        condition: service_healthy
      minio:
        condition: service_healthy
    ports:
      - "9083:9083"
    environment:
      SERVICE_NAME: metastore
      DB_TYPE: postgres
      POSTGRES_DATABASE: metastore
      POSTGRES_HOST: postgres_hive
      POSTGRES_USER: hive
      POSTGRES_PASSWORD: hivepassword
      AWS_ACCESS_KEY_ID: admin
      AWS_SECRET_ACCESS_KEY: password123
      AWS_S3_ENDPOINT: http://minio:9000
      HADOOP_AWS_S3_PATHSTYLEACCESS: "true"
      HIVE_METASTORE_WAREHOUSE_DIR: s3a://warehouse/
    command: /opt/hive/bin/hive --service metastore
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "9083"]
      interval: 60s
      timeout: 30s
      retries: 5

  spark-master:
    image: bitnami/spark:3.5
    container_name: spark-master
    networks:
      - agri_platform_net
    ports:
      - "8080:8080"
      - "7077:7077"
    volumes:
      - ./spark_jobs:/opt/bitnami/spark/jobs
      - ./config/spark/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf:ro
      - ./services/curation_platform:/opt/bitnami/spark/curation_platform_jobs
    environment:
      SPARK_MODE: master
      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: "no"
      SPARK_SSL_ENABLED: "no"
      SPARK_MASTER_OPTS: "-Dspark.deploy.recoveryMode=NONE"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 30s
      timeout: 10s
      retries: 5

  spark-worker:
    image: bitnami/spark:3.5
    container_name: spark-worker
    networks:
      - agri_platform_net
    depends_on:
      spark-master:
        condition: service_healthy
      minio:
        condition: service_healthy
      hive-metastore:
        condition: service_healthy
    volumes:
      - ./spark_jobs:/opt/bitnami/spark/jobs
      - ./config/spark/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf:ro
      - ./services/curation_platform:/opt/bitnami/spark/curation_platform_jobs
    environment:
      SPARK_MODE: worker
      SPARK_MASTER_URL: spark://spark-master:7077
      SPARK_WORKER_MEMORY: 2G
      SPARK_WORKER_CORES: 2
      SPARK_RPC_AUTHENTICATION_ENABLED: "no"
      SPARK_RPC_ENCRYPTION_ENABLED: "no"
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: "no"
      SPARK_SSL_ENABLED: "no"

  trino-coordinator:
    image: trinodb/trino:latest
    container_name: trino-coordinator
    networks:
      - agri_platform_net
    ports:
      - "8081:8080"
    depends_on:
      hive-metastore:
        condition: service_healthy
      minio:
        condition: service_healthy
    volumes:
      - ./trino_catalogs:/etc/trino/catalog
    environment:
      TRINO_ENVIRONMENT: "development"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/v1/info"]
      interval: 30s
      timeout: 10s
      retries: 5

  clickhouse:
    image: clickhouse/clickhouse-server:latest
    container_name: clickhouse
    networks:
      - agri_platform_net
    ports:
      - "8123:8123"
      - "9002:9000"
    ulimits:
      nofile: { soft: 262144, hard: 262144 }
    environment:
      CLICKHOUSE_USER: user
      CLICKHOUSE_PASSWORD: password
      CLICKHOUSE_DB: agri_db
    volumes:
      - clickhouse_data:/var/lib/clickhouse
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8123/ping"]
      interval: 30s
      timeout: 10s
      retries: 5

  redis:
    image: redis:7-alpine
    container_name: redis
    networks:
      - agri_platform_net
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  postgres_superset:
    image: postgres:15-alpine
    container_name: postgres_superset
    networks:
      - agri_platform_net
    ports:
      - "5433:5432"
    environment:
      POSTGRES_DB: superset
      POSTGRES_USER: superset
      POSTGRES_PASSWORD: supersetpassword
    volumes:
      - postgres_superset_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U superset -d superset"]
      interval: 10s
      timeout: 5s
      retries: 5

  superset:
    image: apache/superset:latest
    container_name: superset
    networks:
      - agri_platform_net
    depends_on:
      postgres_superset:
        condition: service_healthy
      redis:
        condition: service_healthy
    ports:
      - "8088:8088"
    environment:
      SUPERSET_SECRET_KEY: "your-secret-key-change-this-in-production"
      SUPERSET_CONFIG_PATH: "/app/pythonpath/superset_config.py"
      PYTHONPATH: "/app/pythonpath"
      POSTGRES_USER: superset
      POSTGRES_PASSWORD: supersetpassword
      POSTGRES_HOST: postgres_superset
      POSTGRES_PORT: 5432
      POSTGRES_DB: superset
      REDIS_HOST: redis
      REDIS_PORT: 6379
      SUPERSET_LOAD_EXAMPLES: "false"
    volumes:
      - ./superset_config/superset_config.py:/app/pythonpath/superset_config.py:ro
      - ./superset_config/requirements-local.txt:/app/requirements-local.txt:ro
    user: "root"
    entrypoint: >
      bash -c "
        if [ ! -f /app/superset_init_done ]; then
          echo 'Inicializando Superset...' &&
          pip install --no-cache-dir -r /app/requirements-local.txt &&
          superset db upgrade &&
          superset fab create-admin --username admin --firstname Admin --lastname User --email admin@superset.com --password admin &&
          superset init &&
          touch /app/superset_init_done;
        fi;
        /usr/bin/run-server.sh -p 8088 --with-threads --reload --debugger;
      "
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8088/health"]
      interval: 60s
      timeout: 30s
      retries: 5

  producer_simulator:
    build:
      context: ./services/producer_simulator
      dockerfile: Dockerfile
    container_name: producer_simulator
    networks:
      - agri_platform_net
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_BOOTSTRAP_SERVERS: kafka:9092
      KAFKA_TOPIC: raw_land_data
      SIMULATION_DELAY_SECONDS: 5
    restart: unless-stopped

  feast_serve:
    image: feastdev/feature-server:0.32.0
    container_name: feast_serve
    networks:
      - agri_platform_net
    depends_on:
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
    ports:
      - "6566:6566"
    volumes:
      - ./feast_repo:/feature_repo
    environment:
      FEAST_USAGE: "False"
      AWS_ACCESS_KEY_ID: admin
      AWS_SECRET_ACCESS_KEY: password123
      AWS_DEFAULT_REGION: us-east-1
      AWS_S3_ENDPOINT_URL: http://minio:9000
    working_dir: /feature_repo
    command: ["feast", "serve", "--host", "0.0.0.0", "--port", "6566"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6566/health"]
      interval: 30s
      timeout: 10s
      retries: 5

  # dbt_trino_service:
  #   image: ghcr.io/dbt-labs/dbt-trino:latest
  #   container_name: dbt_trino_service
  #   networks:
  #     - agri_platform_net
  #   depends_on:
  #     trino-coordinator:
  #       condition: service_healthy
  #   volumes:
  #     - ./dbt_project:/usr/app/dbt_project
  #     - ./dbt_profiles/profiles.yml:/root/.dbt/profiles.yml:ro
  #   working_dir: /usr/app/dbt_project
  #   entrypoint: >
  #     /bin/sh -c "
  #       echo 'dbt-trino service pronto para uso.' &&
  #       echo 'Execute: docker-compose exec dbt_trino_service dbt run' &&
  #       tail -f /dev/null
  #     "